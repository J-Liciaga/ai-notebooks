{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "a fundamental classification algorithm in ML. It's used for binary classification problems, not regression. It's widely used in various fields, including medicine, finance, marketing, and more. \n",
    "\n",
    "At it's core, logistic regression is a linear model that predicts the probability than an instance belongs to a particular class. If the estimated probability is greater than 50%, then the model predicts that the instance belongs to that class (positive class, usually labeled as 1), otherwise it predicts that it doesn't (negative class, usually labeled as 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample data\n",
    "X = torch.randn(100, 1)\n",
    "y = (X > 0).float()  # Binary classification target\n",
    "\n",
    "# define model\n",
    "model = LogisticRegressionModel(1, 1)\n",
    "\n",
    "# define loss and optimizer\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    outputs = model(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "\n",
    "    # backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate the model\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "    y_pred_class = y_pred.round()\n",
    "    accuracy = (y_pred_class == y).float().mean()\n",
    "    print(f'Accuracy: {accuracy.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the decision boundary\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X.numpy(), y.numpy(), c=y.numpy(), cmap='viridis', alpha=0.7)\n",
    "\n",
    "X_plot = torch.linspace(X.min() - 1, X.max() + 1, 100).reshape(-1, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_plot = model(X_plot)\n",
    "\n",
    "plt.plot(X_plot.numpy(), y_plot.numpy(), color='red', label='Decision Boundary')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Logistic Regression Decision Boundary')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
