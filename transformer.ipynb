{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (4.12.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "       \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, q, k, v, mask):\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention_logits = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.depth)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = nn.Softmax(dim=1)(scaled_attention_logits)\n",
    "\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        output = output.permute(0, 2, 1, 3).contiguous()\n",
    "        output = output.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        return self.dense(output)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.linear_a = nn.Linear(d_model, d_ff)\n",
    "        self.linear_b = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_b(nn.ReLU()(self.linear_a(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        \n",
    "        self.layernorm_1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm_2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attention_output = self.multi_head_attention(x, x, x, mask)\n",
    "        out1 = self.layernorm_1(x + self.dropout(attention_output))\n",
    "\n",
    "        ff_output = self.feed_forward(out1)\n",
    "        out2 = self.layernorm_2(out1 + self.dropout(ff_output))\n",
    "\n",
    "        return out2\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.multi_head_attention_2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "\n",
    "        self.layernorm_1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm_2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm_3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attention_output_1 = self.multi_head_attention_1(x, x, x, look_ahead_mask)\n",
    "        out1 = self.layernorm_1(x + self.dropout(attention_output_1))\n",
    "\n",
    "        attention_output_2 = self.multi_head_attention_2(out1, enc_output, enc_output, padding_mask)\n",
    "        out2 = self.layernorm_2(out1 + self.dropout(attention_output_2))\n",
    "\n",
    "        ff_output = self.feed_forward(out2)\n",
    "        out3 = self.layernorm_3(out2 + self.dropout(ff_output))\n",
    "\n",
    "        return out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_ff, input_vocab_size, target_vocab_size, max_seq_len, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_len)\n",
    "        \n",
    "        self.encoder_layers = nn.ModuleList(EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers))\n",
    "        self.decoder_layers = nn.ModuleList(DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers))\n",
    "        self.final_layer = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        src = self.encoder_embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            src = layer(src, src_mask)\n",
    "\n",
    "        return src\n",
    "    \n",
    "    def decode(self, target, memory, target_mask, src_mask):\n",
    "        tgt = self.decoder_embedding(target)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt = layer(tgt, memory, target_mask, src_mask)\n",
    "\n",
    "        return tgt\n",
    "    \n",
    "    def forward(self, src, target, src_mask, target_mask):\n",
    "        enc_output = self.encode(src, src_mask)\n",
    "        dec_output = self.decode(target, enc_output, target_mask, src_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage\n",
    "src_vocab_size = 5000\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_len = 100  # Make sure this matches or exceeds your maximum sequence length\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, d_ff, src_vocab_size, tgt_vocab_size, max_seq_len, dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 50, 5000])\n",
      "Epoch 0, Loss: 8.681242942810059\n",
      "Epoch 10, Loss: 7.785988807678223\n",
      "Epoch 20, Loss: 7.275804042816162\n",
      "Epoch 30, Loss: 6.8224663734436035\n",
      "Epoch 40, Loss: 6.4238409996032715\n",
      "Epoch 50, Loss: 6.083193302154541\n",
      "Epoch 60, Loss: 5.811666488647461\n",
      "Epoch 70, Loss: 5.663562774658203\n",
      "Epoch 80, Loss: 5.583548069000244\n",
      "Epoch 90, Loss: 5.441462993621826\n",
      "Epoch 100, Loss: 5.707009792327881\n",
      "Epoch 110, Loss: 5.517961025238037\n",
      "Epoch 120, Loss: 5.368545055389404\n",
      "Epoch 130, Loss: 5.320172309875488\n",
      "Epoch 140, Loss: 5.121002674102783\n",
      "Epoch 150, Loss: 4.881214618682861\n",
      "Epoch 160, Loss: 4.996980667114258\n",
      "Epoch 170, Loss: 4.8812479972839355\n",
      "Epoch 180, Loss: 4.856856822967529\n",
      "Epoch 190, Loss: 4.76165771484375\n",
      "Epoch 200, Loss: 4.584609508514404\n",
      "Epoch 210, Loss: 4.509925365447998\n",
      "Epoch 220, Loss: 4.376990795135498\n",
      "Epoch 230, Loss: 4.295757293701172\n",
      "Epoch 240, Loss: 4.221035957336426\n",
      "Epoch 250, Loss: 4.446709156036377\n",
      "Epoch 260, Loss: 4.632270812988281\n",
      "Epoch 270, Loss: 5.080401420593262\n",
      "Epoch 280, Loss: 7.13090705871582\n",
      "Epoch 290, Loss: 6.781644344329834\n",
      "Epoch 300, Loss: 5.760133743286133\n",
      "Epoch 310, Loss: 5.617121696472168\n",
      "Epoch 320, Loss: 5.200504302978516\n",
      "Epoch 330, Loss: 5.867919921875\n",
      "Epoch 340, Loss: 5.839981555938721\n",
      "Epoch 350, Loss: 5.312882900238037\n",
      "Epoch 360, Loss: 5.090539932250977\n",
      "Epoch 370, Loss: 4.88245964050293\n",
      "Epoch 380, Loss: 4.671823024749756\n",
      "Epoch 390, Loss: 4.58366060256958\n",
      "Epoch 400, Loss: 4.4600043296813965\n",
      "Epoch 410, Loss: 4.54578971862793\n",
      "Epoch 420, Loss: 5.440253257751465\n",
      "Epoch 430, Loss: 5.516549587249756\n",
      "Epoch 440, Loss: 5.489548206329346\n",
      "Epoch 450, Loss: 5.120459079742432\n",
      "Epoch 460, Loss: 5.563076972961426\n",
      "Epoch 470, Loss: 5.2920708656311035\n",
      "Epoch 480, Loss: 6.7999186515808105\n",
      "Epoch 490, Loss: 7.2886223793029785\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# sample input\n",
    "batch_size = 64\n",
    "seq_length = 50\n",
    "src = torch.randint(1, src_vocab_size, (batch_size, seq_length))\n",
    "tgt = torch.randint(1, tgt_vocab_size, (batch_size, seq_length)) \n",
    "\n",
    "# create masks \n",
    "src_mask = torch.ones(batch_size, 1, 1, seq_length)\n",
    "tgt_mask = torch.tril(torch.ones(batch_size, 1, seq_length, seq_length))\n",
    "\n",
    "# forward pass\n",
    "output = transformer(src, tgt, src_mask, tgt_mask)\n",
    "print(output.shape)  # Expected: torch.Size([64, 50, 5000])\n",
    "\n",
    "# training loop \n",
    "epochs = 500\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0) \n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(src, tgt, src_mask, tgt_mask)\n",
    "    loss = loss_fn(output.view(-1, tgt_vocab_size), tgt.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
